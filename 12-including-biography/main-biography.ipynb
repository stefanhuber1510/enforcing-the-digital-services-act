{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding biographies\n",
    "In this notebook I seek to carry out the same chatGPT experiments with less examples and more clear definitions first. Then I'll compare against previous experiments and finally add the biograhpies as context, to see its influence. I might also try embedding variations. <br>\n",
    "Exact list of planned baseline comparison:\n",
    "1. Embedding of post baseline\n",
    "2. Embedding of post with simple instruction (no CoT)\n",
    "3. Embedding of post with instruction & example (no CoT)\n",
    "4. Embedding of post with instruction, example and CoT\n",
    "5. chatGPT completions all of the above instead of embeddings\n",
    "6. All of the above with Biographies\n",
    "\n",
    "I'll do this with the 200 double checked posts or a similarly sized sample.<br>\n",
    "For flexibility with the prompts, I probably do not want to do this in a modular fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import openai\n",
    "from helpers.GPTclassifier import gptclassifier\n",
    "openai.api_key = \"\"\n",
    "df = pd.read_pickle(\"data/df_sampled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (skip execution) Generating a sample to work with\n",
    "\n",
    "# import instagram profiles\n",
    "profiles = pd.read_pickle(\"data/df_profiles.pkl\")\n",
    "\n",
    "# import posts\n",
    "sys.path.append('../7-Self-Labelled-Data')\n",
    "df = pd.read_pickle(\"../7-Self-Labelled-Data/data/annotated_test_explantions_gpt3.pkl\")\n",
    "\n",
    "# remove extremely long posts\n",
    "df = df[df[\"caption\"].apply(lambda x: len(x)<=500)]\n",
    "# remove the less represented influencers; maintains 70 % of the data\n",
    "df = df[df[\"username\"].isin(df['username'].value_counts().nlargest(20).index)]\n",
    "# sample 10 posts per influencer\n",
    "df_sampled = df.groupby('username', group_keys=False).apply(lambda x: x.sample(min(len(x), 10)))\n",
    "# add biography & co from profiles\n",
    "df_sampled = df_sampled.merge(profiles[['username', 'full_name', 'edge_followed_by', 'biography']], on='username', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"You are an assistant helping an academic to reason about whether a post contains (potentially non-commerical) promotional activity or even is potentially sponsored. I will provide you with the caption of an instagram post as well as maybe the caption of other posts from the same user, so you have more context. You give me a short and concise reasoning why or why not the main post might be an ad, i.e. the result of a financial contract. For later classification there are four labels available, 'Potentially sponsored', 'Self advertisement', 'Ambiguous' and 'Likely not sponsored'. Be concise in your reasoning and always strictly adhere to the pattern from the examples, i.e. always decide for one and only one label and finish your response with it and a dot after. If you are uncertain, err strongly towards 'Potentially sponsored'. Also strongly prefer 'Self advertisement' over 'Ambigous'. Always keep responses short and concise.\"},\n",
    "{\"role\": \"user\", \"content\": \"Main Post: ''I DO NOT OWN THE RIGHTS TO THIS SONG. Upload attempt #2.... I COULD NOT STOP playing this song over Christmas break for some odd reason. It’s my favorite joint off of @badgalriri ‘s #anti album. Listening repeatedly made wonder what it would sound like with drums... 🤔😏 #thepocketqueen 👸🏾♥️🤦🏾\\u200d♀️ #practicemakespocket #jamesjoint #groovewithme #drummerbae\\n\\nHair: @hairbylucylomuro_ \\nThreads: @truequeenbrand'. Author: @thepocketqueen \\n Context Post 1: @erinelijah this is amazing. \\nI appreciate it so much ♥️♠️ \\n#thepocketqueen #pocketqlub♦️♣️ #fanart. \\n Context Post 2: 2 days ago ♠️𝗣𝗼𝗰𝗸𝗲𝘁 𝗤𝘂𝗲𝗲𝗻 & 𝗧𝗵𝗲 𝗥𝗼𝘆𝗮𝗹 𝗙𝗹𝘂𝘀𝗵 ♥️ made its debut performance after placing as a runner up in @nprmusic ‘s #TinyDeskContest  \\nIt’s one thing to do cool stuff. It’s a whole other blessing to be able to do it with your friends. :) BIG thanks to @ryckjane and @iammattrose for coming through and hopping on the mic. \\n📸: @farahstop.\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Key indicators: 'of @badgalriri ‘s #anti album', 'Threads: @truequeenbrand', 'Hair: @hairbylucylomuro'.\\nReasoning: The post clearly promotes a song, another artist @badgalriri. Additionally there are several businesses featured in the. Each of those four aspects by itself is some indication of sponsoring, so all together clearly potentially sponsored. Label: Potentially sponsored.\"},\n",
    "{\"role\": \"user\", \"content\": \"Post: 'I love cheeseburgers so much!😱 @barneysburgershop'. Author: @stevietheking. \\n Context Post 1: [...] \\n Context Post 2: [...]\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Key indicators: '@barneysburgershop'.\\nReasoning: The post clearly promotes a restaurant called barneysburgershop. However it is also extremely common that people feature restaurants because they genuinely enjoy their food or want to show off with it. Lacking further evidence, it rather Ambigous than a paid partnership. Label: Ambiguous.\"},\n",
    "{\"role\": \"user\", \"content\": \"Post: 'She drives me INSANE every other hour, but i don’t know what i would do without her crazy ass! #sisters'. User: @thestilettomeup \\n Context Post 1: [...] \\n Context Post 2: [...]\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Key indicators: '#sisters'.\\nReasoning: Clearly a personal post about the author's sister. Label: Likely not sponsored.\"},\n",
    "{\"role\": \"user\", \"content\": \"Post: 'weworewhat swim spring collection home designs and prints inspired by elements from my home and favorite interior design what you can expect this silhouette print inspired by the many female body sculptures that can be found in my apartment marbles cowhide florals and more @shopweworewhat'. Author: weworewhat \\n Context Post 1: [...] \\n Context Post 2: [...]\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Key indicators: 'weworewhat', '@shopweworewhat'.\\nReasoning: This post clearly advertises swim suits. However the shop @shopweworewhat is clearly a shop of the author weworewhat herself, so its very unlikely a paid partnership but clearly self advertisement. Label: Self advertisement.\"},\n",
    "{\"role\": \"user\", \"content\": \"Post: 'A night in San Francisco 💋 I am so excited to meet all of the @createcultivate attendees and share more of my story... #moreofwhatmatters \\nTop: @storets \\nPants : @jacquemus \\nShoes: @gianvitorossi \\nStyled By: @monicarosestyle'. Author: iamcattsadler. \\n Context Post 1: She’s becoming such a young lady and it’s all happening so fast! \\nMy sweet heart! 💚 \\nMatching outfits from @byegreis + @ivygreis. \\n Context Post 2: Legs or shoes? Take your pick! 😜 \\nNew booties @aminamuaddiofficial \\nI love me a good platform!\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Key indicators: 'Top: @storets', 'Pants : @jacquemus', 'Shoes: @gianvitorossi', 'Styled By: @monicarosestyle'.\\nReasoning: This post promotes various fashion brands and stylers. There is no evidence suggesting it is not paid. Label: Potentially sponsored.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356\n",
      "1018\n",
      "932\n",
      "628\n",
      "897\n",
      "662\n",
      "798\n",
      "287\n",
      "1110\n",
      "294\n"
     ]
    }
   ],
   "source": [
    "for row in df[30:40].iterrows():\n",
    "    print(len(row[1]['caption']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter at 2\n",
      "Counter at 7\n",
      "Counter at 12\n",
      "Counter at 17\n",
      "Counter at 22\n",
      "Counter at 27\n",
      "Counter at 32\n",
      "Counter at 37\n",
      "Waiting for 65s InvalidRequestError\n",
      "-----------------\n",
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4185 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m, in \u001b[0;36mgptclassifier\u001b[0;34m(df, messages, completions, timer_frequency)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     19\u001b[0m                                         messages\u001b[39m=\u001b[39;49mmessages)\n\u001b[1;32m     20\u001b[0m     completions\u001b[39m.\u001b[39mappend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/UM-final-semester/thesis/enforcing-the-digital-services-act/thesis-venv/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/UM-final-semester/thesis/enforcing-the-digital-services-act/thesis-venv/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    138\u001b[0m (\n\u001b[1;32m    139\u001b[0m     deployment_id,\n\u001b[1;32m    140\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m )\n\u001b[0;32m--> 153\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m     url,\n\u001b[1;32m    156\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/UM-final-semester/thesis/enforcing-the-digital-services-act/thesis-venv/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m )\n\u001b[0;32m--> 226\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/UM-final-semester/thesis/enforcing-the-digital-services-act/thesis-venv/lib/python3.9/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    624\u001b[0m         ),\n\u001b[1;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m~/UM-final-semester/thesis/enforcing-the-digital-services-act/thesis-venv/lib/python3.9/site-packages/openai/api_requestor.py:679\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 679\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    680\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    681\u001b[0m     )\n\u001b[1;32m    682\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, your messages resulted in 4185 tokens. Please reduce the length of the messages.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# execute classification\u001b[39;00m\n\u001b[1;32m      2\u001b[0m completions_classic \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m results \u001b[39m=\u001b[39m gptclassifier(df\u001b[39m.\u001b[39;49mreset_index(drop\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),messages,completions_classic)\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mgptclassifier\u001b[0;34m(df, messages, completions, timer_frequency)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-----------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(err)\n\u001b[0;32m---> 25\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m65\u001b[39;49m)\n\u001b[1;32m     26\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mcreate(model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m                                         messages\u001b[39m=\u001b[39mmessages)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# execute classification: 3 per minute\n",
    "completions_classic = []\n",
    "results = gptclassifier(df.reset_index(drop=True),messages,completions_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       30\n",
       "1      130\n",
       "2       49\n",
       "3      339\n",
       "4      101\n",
       "      ... \n",
       "195    453\n",
       "196    342\n",
       "197    206\n",
       "198    363\n",
       "199    551\n",
       "Name: caption, Length: 200, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[\"caption\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import time\n",
    "\n",
    "def gptclassifier(df,base_messages,completions,timer_frequency=5):\n",
    "\n",
    "    i=0    \n",
    "    for txt in df.loc[:,[\"caption\",\"username\"]].iterrows():\n",
    "        \n",
    "        # timer\n",
    "        i+=1\n",
    "        if i%timer_frequency==2:\n",
    "            print(f\"Counter at {i}\")\n",
    "\n",
    "        messages = base_messages.copy()\n",
    "        messages.append({\"role\": \"user\", \"content\": f\"Post: '{txt[1]['caption']}'. User: @{txt[1]['username']}\"})\n",
    "        # try except to prevent openAIs limits\n",
    "        print(messages[-1])\n",
    "        print(base_messages[-1])\n",
    "        if i ==3:return\n",
    "        \n",
    "    return completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': \"Post: 'Cook-off w/ friends dropped @6pm click the link in bio to watch now || sorry for the late notice I was slumped😭😂'. User: @cleopatraa_duess\"}\n",
      "{'role': 'assistant', 'content': \"Key indicators: 'Top: @storets', 'Pants : @jacquemus', 'Shoes: @gianvitorossi', 'Styled By: @monicarosestyle'.\\nReasoning: This post promotes various fashion brands and stylers. There is no evidence suggesting it is not paid. Label: Potentially sponsored.\"}\n",
      "Counter at 2\n",
      "{'role': 'user', 'content': \"Post: 'Back at the office 💛\\n\\nYellow is my absolute favorite color! There’s nothing like it! \\n\\nOutfit @byegreis \\nBag @dior \\nShoes @hermes'. User: @thestilettomeup\"}\n",
      "{'role': 'assistant', 'content': \"Key indicators: 'Top: @storets', 'Pants : @jacquemus', 'Shoes: @gianvitorossi', 'Styled By: @monicarosestyle'.\\nReasoning: This post promotes various fashion brands and stylers. There is no evidence suggesting it is not paid. Label: Potentially sponsored.\"}\n",
      "{'role': 'user', 'content': \"Post: 'On a global tour with you #venice edition! 🛶🛶\\nThe best part of travelling the globe is doing it with loved ones. Sharing Experiences and making memories that will last a lifetime \\nPhoto round up form @amfar luncheon and gala dinner at #venicefilmfestival'. User: @hofitgolanofficial\"}\n",
      "{'role': 'assistant', 'content': \"Key indicators: 'Top: @storets', 'Pants : @jacquemus', 'Shoes: @gianvitorossi', 'Styled By: @monicarosestyle'.\\nReasoning: This post promotes various fashion brands and stylers. There is no evidence suggesting it is not paid. Label: Potentially sponsored.\"}\n"
     ]
    }
   ],
   "source": [
    "gptclassifier(df.reset_index(drop=True),messages,completions_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next steps:\n",
    "# 1. study failure cases\n",
    "# 2. adjust the prompt\n",
    "# 3. expand experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for later: has already context post hints\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are an assistant helping an academic to reason about whether a post contains (potentially non-commerical) promotional activity or even is potentially sponsored. I will provide you with the caption of an instagram post as well as maybe the caption of other posts from the same user, so you have more context. You give me a short and concise reasoning why or why not the main post might be an ad, i.e. the result of a financial contract. For later classification there are four labels available, 'Potentially sponsored', 'Self advertisement', 'Ambiguous' and 'Likely not sponsored'. Be concise in your reasoning and always strictly adhere to the pattern from the examples, i.e. always decide for one and only one label and finish your response with it and a dot after. If you are uncertain, err strongly towards 'Potentially sponsored'. Also strongly prefer 'Self advertisement' over 'Ambigous'. Always keep responses short and concise.\"},\n",
    "{\"role\": \"user\", \"content\": \"Main Post: ''I DO NOT OWN THE RIGHTS TO THIS SONG. Upload attempt #2.... I COULD NOT STOP playing this song over Christmas break for some odd reason. It’s my favorite joint off of @badgalriri ‘s #anti album. Listening repeatedly made wonder what it would sound like with drums... 🤔😏 #thepocketqueen 👸🏾♥️🤦🏾\\u200d♀️ #practicemakespocket #jamesjoint #groovewithme #drummerbae\\n\\nHair: @hairbylucylomuro_ \\nThreads: @truequeenbrand'. Author: @thepocketqueen \\n Context Post 1: @erinelijah this is amazing. \\nI appreciate it so much ♥️♠️ \\n#thepocketqueen #pocketqlub♦️♣️ #fanart. \\n Context Post 2: 2 days ago ♠️𝗣𝗼𝗰𝗸𝗲𝘁 𝗤𝘂𝗲𝗲𝗻 & 𝗧𝗵𝗲 𝗥𝗼𝘆𝗮𝗹 𝗙𝗹𝘂𝘀𝗵 ♥️ made its debut performance after placing as a runner up in @nprmusic ‘s #TinyDeskContest  \\nIt’s one thing to do cool stuff. It’s a whole other blessing to be able to do it with your friends. :) BIG thanks to @ryckjane and @iammattrose for coming through and hopping on the mic. \\n📸: @farahstop.\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Key indicators: 'of @badgalriri ‘s #anti album', 'Threads: @truequeenbrand', 'Hair: @hairbylucylomuro'.\\nReasoning: The post clearly promotes a song, another artist @badgalriri. Additionally there are several businesses featured in the. Each of those four aspects by itself is some indication of sponsoring, so all together clearly potentially sponsored. Label: Potentially sponsored.\"},\n",
    "{\"role\": \"user\", \"content\": \"Post: 'I love cheeseburgers so much!😱 @barneysburgershop'. Author: @stevietheking. \\n Context Post 1: [...] \\n Context Post 2: [...]\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Key indicators: '@barneysburgershop'.\\nReasoning: The post clearly promotes a restaurant called barneysburgershop. However it is also extremely common that people feature restaurants because they genuinely enjoy their food or want to show off with it. Lacking further evidence, it rather Ambigous than a paid partnership. Label: Ambiguous.\"},\n",
    "{\"role\": \"user\", \"content\": \"Post: 'She drives me INSANE every other hour, but i don’t know what i would do without her crazy ass! #sisters'. User: @thestilettomeup \\n Context Post 1: [...] \\n Context Post 2: [...]\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Key indicators: '#sisters'.\\nReasoning: Clearly a personal post about the author's sister. Label: Likely not sponsored.\"},\n",
    "{\"role\": \"user\", \"content\": \"Post: 'weworewhat swim spring collection home designs and prints inspired by elements from my home and favorite interior design what you can expect this silhouette print inspired by the many female body sculptures that can be found in my apartment marbles cowhide florals and more @shopweworewhat'. Author: weworewhat \\n Context Post 1: [...] \\n Context Post 2: [...]\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Key indicators: 'weworewhat', '@shopweworewhat'.\\nReasoning: This post clearly advertises swim suits. However the shop @shopweworewhat is clearly a shop of the author weworewhat herself, so its very unlikely a paid partnership but clearly self advertisement. Label: Self advertisement.\"},\n",
    "{\"role\": \"user\", \"content\": \"Post: 'A night in San Francisco 💋 I am so excited to meet all of the @createcultivate attendees and share more of my story... #moreofwhatmatters \\nTop: @storets \\nPants : @jacquemus \\nShoes: @gianvitorossi \\nStyled By: @monicarosestyle'. Author: iamcattsadler. \\n Context Post 1: She’s becoming such a young lady and it’s all happening so fast! \\nMy sweet heart! 💚 \\nMatching outfits from @byegreis + @ivygreis. \\n Context Post 2: Legs or shoes? Take your pick! 😜 \\nNew booties @aminamuaddiofficial \\nI love me a good platform!\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Key indicators: 'Top: @storets', 'Pants : @jacquemus', 'Shoes: @gianvitorossi', 'Styled By: @monicarosestyle'.\\nReasoning: This post promotes various fashion brands and stylers. There is no evidence suggesting it is not paid. Label: Potentially sponsored.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
