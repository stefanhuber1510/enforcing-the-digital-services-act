{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import openai\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import json\n",
    "\n",
    "# import large file\n",
    "with open('../ct_df_posts_single_preds.pkl', 'rb') as f:\n",
    "    pre_df = pkl.load(f)\n",
    "\n",
    "# shorten to not murder my computer\n",
    "# df = pre_df.iloc[:50]\n",
    "#del pre_df\n",
    "\n",
    "# retrieve API key\n",
    "import os\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "# print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only get the ones without disclosures\n",
    "pre_df = pre_df[pre_df[\"has_disclosures\"]==False]\n",
    "\n",
    "# sample 50 ads, 50 non-ads\n",
    "df = pd.concat([pre_df[pre_df.loc[:,\"predicted_disclosure\"]==True].sample(50),\n",
    "                pre_df[pre_df.loc[:,\"predicted_disclosure\"]==False].sample(50)]).copy()\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "del pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pompt2\n",
      "Counter at 10\n",
      "Counter at 20\n",
      "Counter at 30\n",
      "Counter at 40\n",
      "Counter at 50\n",
      "Counter at 60\n",
      "Counter at 70\n",
      "Counter at 80\n",
      "Counter at 90\n",
      "Counter at 100\n",
      "text-davinci-002 done\n",
      "pompt1\n",
      "Counter at 10\n",
      "Counter at 20\n",
      "Counter at 30\n",
      "Counter at 40\n",
      "Counter at 50\n",
      "Counter at 60\n",
      "Counter at 70\n",
      "Counter at 80\n",
      "Counter at 90\n",
      "Counter at 100\n",
      "text-ada-001 done\n",
      "pompt1\n",
      "Counter at 10\n",
      "Counter at 20\n",
      "Counter at 30\n",
      "Counter at 40\n",
      "Counter at 50\n",
      "Counter at 60\n",
      "Counter at 70\n",
      "Counter at 80\n",
      "Counter at 90\n",
      "Counter at 100\n",
      "text-babbage-001 done\n",
      "pompt2\n",
      "Counter at 10\n",
      "Counter at 20\n",
      "Counter at 30\n",
      "Counter at 40\n",
      "Counter at 50\n",
      "Counter at 60\n",
      "Counter at 70\n",
      "Counter at 80\n",
      "Counter at 90\n",
      "Counter at 100\n",
      "text-curie-001 done\n"
     ]
    }
   ],
   "source": [
    "# Generate classifications for all samples\n",
    "\n",
    "completions = {\"text-ada-001\":[], \"text-babbage-001\":[], \"text-curie-001\":[], \"text-davinci-002\":[]}\n",
    "for model in [\"text-davinci-002\",\"text-ada-001\", \"text-babbage-001\", \"text-curie-001\"]:\n",
    "    i=0\n",
    "    for txt in df.loc[:,\"caption\"]:\n",
    "        i+=1\n",
    "        if i%10==0: print(f\"Counter at {i}\")\n",
    "\n",
    "        # timer to stay within my quota\n",
    "        if i==24: time.sleep(65)\n",
    "        if i==49: time.sleep(65)\n",
    "        if i==74: time.sleep(65)\n",
    "        if i==99: time.sleep(65)\n",
    "\n",
    "        prompt1 = f\"Judge whether it is likely that the following caption comes from a post that has been sponsored. If you are very uncertain err rather towards judging 'False'.\\n\\n Post: 'aaaa meu look de hoje é da @cea_brasil ❤️ patrocinadora e dona do look oficial do Rock in Rio! Aproveitem pra acompanhar o perfil da C&A pra ver todos os lookinhos maravilhosos! Amo muito! ❤️'\\n Sponsored (True/False): True\\n\\n Post: 'side by side ~ sisters ❤️'\\n Sponsored (True/False): True\\n\\n Post:{txt}\\n Sponsored (True/False):\"\n",
    "        \n",
    "        prompt2 = f\"Judge whether it is likely that the following caption comes from a post that has been sponsored. If you are very uncertain err rather towards judging 'True'.\\n\\n Post: 'aaaa meu look de hoje é da @cea_brasil ❤️ patrocinadora e dona do look oficial do Rock in Rio! Aproveitem pra acompanhar o perfil da C&A pra ver todos os lookinhos maravilhosos! Amo muito! ❤️'\\n Sponsored (True/False): True\\n\\n Post: 'side by side ~ sisters ❤️'\\n Sponsored (True/False): True\\n\\n Post:{txt}\\n Sponsored (True/False):\"\n",
    "\n",
    "        # Generate a response from openai.\n",
    "        # Flexibly choose ada/babbage/curie/davinci as engine. For davinci, use text-davinci-002.\n",
    "        prompt=(\"warning\")\n",
    "        if model in [\"text-ada-001\", \"text-babbage-001\"]:\n",
    "            if i==1: print(\"pompt1\")\n",
    "            prompt=prompt1\n",
    "        elif model in [\"text-curie-001\", \"text-davinci-002\"]:\n",
    "            if i==1: print(\"pompt2\")\n",
    "            prompt=prompt2\n",
    "        else:\n",
    "            print(\"warning\")\n",
    "        response = openai.Completion.create(\n",
    "            engine=model,\n",
    "            prompt=prompt,\n",
    "            max_tokens=5,\n",
    "            n=3,\n",
    "            stop=None,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        # Save the response text\n",
    "        completions[model].append(response[\"choices\"][0][\"text\"])\n",
    "    print(model+\" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save interrupted run\n",
    "temp_completions = completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7 43]\n",
      " [ 2 48]]\n",
      "[[36 14]\n",
      " [32 18]]\n",
      "[[45  5]\n",
      " [31 19]]\n",
      "[[49  1]\n",
      " [43  7]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions to booleans\n",
    "completions_as_boolean = {}\n",
    "for model in [\"text-ada-001\", \"text-babbage-001\", \"text-curie-001\", \"text-davinci-002\"]:\n",
    "    completions_as_boolean[model] = [True if response.__contains__(\"rue\") \n",
    "                          else False if response.__contains__(\"als\")\n",
    "                          else \"warning\" for response in completions[model]]\n",
    "\n",
    "    # check for bad completions\n",
    "    if \"warning\" in completions[model]: print(\"Warning\")\n",
    "\n",
    "    # obtain confusion matrix\n",
    "\n",
    "    print(confusion_matrix(df[\"predicted_disclosure\"],completions_as_boolean[model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' True',\n",
       " ' False',\n",
       " ' True',\n",
       " ' False',\n",
       " ' True',\n",
       " ' False',\n",
       " ' False',\n",
       " ' True',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' True',\n",
       " ' True',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' True',\n",
       " ' False',\n",
       " ' True',\n",
       " ' True',\n",
       " ' False',\n",
       " ' True',\n",
       " ' False',\n",
       " ' True',\n",
       " ' True',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' True',\n",
       " ' True',\n",
       " ' True',\n",
       " ' True',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " '\\n\\nTrue',\n",
       " ' True',\n",
       " ' False',\n",
       " ' True',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' True',\n",
       " ' True',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' True',\n",
       " ' False',\n",
       " '\\n\\nFalse',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " '\\n\\nTrue',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' True',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False',\n",
       " ' False']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completions[\"text-curie-001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.pkl', 'rb') as f:\n",
    "    pre_df = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39msum\u001b[39;49m(completions[\u001b[39m\"\u001b[39;49m\u001b[39mtext-ada-001\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "# next steps: translate strings to bool and compare different results to what he got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before doing this, add something like the true values\n",
    "with open('results.pkl', 'wb') as file:\n",
    "    pkl.dump(completions, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the prompt to get davinci to more positive judgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 45\u001b[0m\n\u001b[1;32m     35\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mCompletion\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m     36\u001b[0m         engine\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext-davinci-002\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m         prompt\u001b[39m=\u001b[39mprompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m         temperature\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     44\u001b[0m     \u001b[39m# Save the response text\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     completions[x]\u001b[39m.\u001b[39mappend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     46\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m done\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Generate classifications for all samples\n",
    "\n",
    "completions ={} #{\"text-ada-001\":[], \"text-babbage-001\":[], \"text-curie-001\":[], \"text-davinci-002\":[]}\n",
    "\n",
    "for x in range(2):#,\"text-ada-001\", \"text-babbage-001\", \"text-curie-001\"]:\n",
    "    i=0\n",
    "    for txt in df.loc[:,\"caption\"]:\n",
    "        i+=1\n",
    "        if i%10==0: print(f\"Counter at {i}\")\n",
    "\n",
    "        # timer to stay within my quota\n",
    "        if i==24: time.sleep(65)\n",
    "        if i==49: time.sleep(65)\n",
    "        if i==74: time.sleep(65)\n",
    "        if i==99: time.sleep(65)\n",
    "        \n",
    "        if x == 0:\n",
    "            prompt = f\"Judge whether it is likely that the following caption comes from a post that has been sponsored. If you are very uncertain err rather towards judging 'True'.\\n\\n Post: 'aaaa meu look de hoje é da @cea_brasil ❤️ patrocinadora e dona do look oficial do Rock in Rio! Aproveitem pra acompanhar o perfil da C&A pra ver todos os lookinhos maravilhosos! Amo muito! ❤️'\\n Sponsored (True/False): True\\n\\n Post: 'side by side ~ sisters ❤️'\\n Sponsored (True/False): True\\n\\n Post:{txt}\\n Sponsored (True/False):\"\n",
    "        elif x ==1:\n",
    "            prompt = f\"Judge whether it is likely that the following caption comes from a post that has been sponsored. If you are not sure, judge 'True'.\\n\\n Post: 'aaaa meu look de hoje é da @cea_brasil ❤️ patrocinadora e dona do look oficial do Rock in Rio! Aproveitem pra acompanhar o perfil da C&A pra ver todos os lookinhos maravilhosos! Amo muito! ❤️'\\n Sponsored (True/False): True\\n\\n Post: 'side by side ~ sisters ❤️'\\n Sponsored (True/False): True\\n\\n Post:{txt}\\n Sponsored (True/False):\"\n",
    "\n",
    "        \n",
    "\n",
    "        # Generate a response from openai.\n",
    "        # Flexibly choose ada/babbage/curie/davinci as engine. For davinci, use text-davinci-002.\n",
    "        #prompt=(\"warning\")\n",
    "        #if model in [\"text-ada-001\", \"text-babbage-001\"]:\n",
    "        #    if i==1: print(\"pompt1\")\n",
    "        #    prompt=prompt1\n",
    "        #elif model in [\"text-curie-001\", \"text-davinci-002\"]:\n",
    "        #    if i==1: print(\"pompt2\")\n",
    "        #    prompt=prompt2\n",
    "        #else:\n",
    "        #    print(\"warning\")\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-002\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=5,\n",
    "            n=3,\n",
    "            stop=None,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        # Save the response text\n",
    "        completions[x].append(response[\"choices\"][0][\"text\"])\n",
    "    print(model+\" done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
