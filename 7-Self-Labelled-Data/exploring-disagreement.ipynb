{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our human annnotations we found severe disagreement between annotators. In this file\n",
    "- I perform some preliminary explorations on the nature of this disagreement\n",
    "- I run GPT-4 labelling on all other samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files in this repository\n",
    "1. new_annotated_sample.pkl: the ~1200 samples with labels generated by us\n",
    "2. annotated_test.pkl: exactly the same\n",
    "3. annotated_val.pkl: labels by law students\n",
    "4. disagreement_sample.json: the 50 overlapping samples, where almost 50% disagreement is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('disagreement_sample.json')\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 occurs 9 times\n",
      "2 occurs 6 times\n",
      "3 occurs 4 times\n",
      "4 occurs 5 times\n"
     ]
    }
   ],
   "source": [
    "labels = [sample[\"label\"] for sample in data]\n",
    "sums = [sum(sample) for sample in labels]\n",
    "\n",
    "for i in set(sums):\n",
    "    print(f\"{i} occurs {sums.count(i)} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.50\n",
       "1    0.08\n",
       "2    0.54\n",
       "3    0.54\n",
       "4    0.54\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding out how often each labeller assigned label 1\n",
    "# all around 50%, except labeller 2\n",
    "labels = pd.DataFrame(labels)\n",
    "(labels.sum(axis=0)/len(labels)).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get explanations for the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"new_annotated_sample.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../99-other-project')\n",
    "from gptClassifier2 import gptclassifier, standard_message\n",
    "\n",
    "openai.api_key = \"\" # insert your api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter at 1\n"
     ]
    }
   ],
   "source": [
    "# execute classification\n",
    "completions=[]\n",
    "results = gptclassifier(df, standard_message, completions, timer_frequency=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
