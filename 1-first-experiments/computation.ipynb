{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import openai\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import json\n",
    "\n",
    "# import large file\n",
    "with open('../ct_df_posts_single_preds.pkl', 'rb') as f:\n",
    "    pre_df = pkl.load(f)\n",
    "\n",
    "# shorten to not murder my computer\n",
    "# df = pre_df.iloc[:50]\n",
    "#del pre_df\n",
    "\n",
    "# retrieve API key\n",
    "import os\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "# print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only get the ones without disclosures\n",
    "pre_df = pre_df[pre_df[\"has_disclosures\"]==False]\n",
    "\n",
    "# sample 50 ads, 50 non-ads\n",
    "df = pd.concat([pre_df[pre_df.loc[:,\"predicted_disclosure\"]==True].sample(15),\n",
    "                pre_df[pre_df.loc[:,\"predicted_disclosure\"]==False].sample(15)]).copy()\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "del pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pompt2\n",
      "Counter at 10\n",
      "Counter at 20\n",
      "Counter at 30\n",
      "Counter at 40\n",
      "Counter at 50\n",
      "Counter at 60\n",
      "Counter at 70\n",
      "Counter at 80\n",
      "Counter at 90\n",
      "Counter at 100\n",
      "text-davinci-002 done\n",
      "pompt1\n",
      "Counter at 10\n",
      "Counter at 20\n",
      "Counter at 30\n",
      "Counter at 40\n",
      "Counter at 50\n",
      "Counter at 60\n",
      "Counter at 70\n",
      "Counter at 80\n",
      "Counter at 90\n",
      "Counter at 100\n",
      "text-ada-001 done\n",
      "pompt1\n",
      "Counter at 10\n",
      "Counter at 20\n",
      "Counter at 30\n",
      "Counter at 40\n",
      "Counter at 50\n",
      "Counter at 60\n",
      "Counter at 70\n",
      "Counter at 80\n",
      "Counter at 90\n",
      "Counter at 100\n",
      "text-babbage-001 done\n",
      "pompt2\n",
      "Counter at 10\n",
      "Counter at 20\n",
      "Counter at 30\n",
      "Counter at 40\n",
      "Counter at 50\n",
      "Counter at 60\n",
      "Counter at 70\n",
      "Counter at 80\n",
      "Counter at 90\n",
      "Counter at 100\n",
      "text-curie-001 done\n"
     ]
    }
   ],
   "source": [
    "# Generate classifications for all samples\n",
    "\n",
    "completions = {\"text-ada-001\":[], \"text-babbage-001\":[], \"text-curie-001\":[], \"text-davinci-002\":[]}\n",
    "for model in [\"text-davinci-002\",\"text-ada-001\", \"text-babbage-001\", \"text-curie-001\"]:\n",
    "    i=0\n",
    "    for txt in df.loc[:,\"caption\"]:\n",
    "        i+=1\n",
    "        if i%10==0: print(f\"Counter at {i}\")\n",
    "\n",
    "        # timer to stay within my quota\n",
    "        if i==24: time.sleep(65)\n",
    "        if i==49: time.sleep(65)\n",
    "        if i==74: time.sleep(65)\n",
    "        if i==99: time.sleep(65)\n",
    "\n",
    "        prompt1 = f\"Judge whether it is likely that the following caption comes from a post that has been sponsored. If you are very uncertain err rather towards judging 'False'.\\n\\n Post: 'aaaa meu look de hoje √© da @cea_brasil ‚ù§Ô∏è patrocinadora e dona do look oficial do Rock in Rio! Aproveitem pra acompanhar o perfil da C&A pra ver todos os lookinhos maravilhosos! Amo muito! ‚ù§Ô∏è'\\n Sponsored (True/False): True\\n\\n Post: 'side by side ~ sisters ‚ù§Ô∏è'\\n Sponsored (True/False): True\\n\\n Post:{txt}\\n Sponsored (True/False):\"\n",
    "        \n",
    "        prompt2 = f\"Judge whether it is likely that the following caption comes from a post that has been sponsored. If you are very uncertain err rather towards judging 'True'.\\n\\n Post: 'aaaa meu look de hoje √© da @cea_brasil ‚ù§Ô∏è patrocinadora e dona do look oficial do Rock in Rio! Aproveitem pra acompanhar o perfil da C&A pra ver todos os lookinhos maravilhosos! Amo muito! ‚ù§Ô∏è'\\n Sponsored (True/False): True\\n\\n Post: 'side by side ~ sisters ‚ù§Ô∏è'\\n Sponsored (True/False): True\\n\\n Post:{txt}\\n Sponsored (True/False):\"\n",
    "\n",
    "        # Generate a response from openai.\n",
    "        # Flexibly choose ada/babbage/curie/davinci as engine. For davinci, use text-davinci-002.\n",
    "        prompt=(\"warning\")\n",
    "        if model in [\"text-ada-001\", \"text-babbage-001\"]:\n",
    "            if i==1: print(\"pompt1\")\n",
    "            prompt=prompt1\n",
    "        elif model in [\"text-curie-001\", \"text-davinci-002\"]:\n",
    "            if i==1: print(\"pompt2\")\n",
    "            prompt=prompt2\n",
    "        else:\n",
    "            print(\"warning\")\n",
    "        response = openai.Completion.create(\n",
    "            engine=model,\n",
    "            prompt=prompt,\n",
    "            max_tokens=5,\n",
    "            n=3,\n",
    "            stop=None,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        # Save the response text\n",
    "        completions[model].append(response[\"choices\"][0][\"text\"])\n",
    "    print(model+\" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge whether it is likely that the following caption comes from a post that has been sponsored. If you are very uncertain err rather towards judging 'False'.\n",
      "\n",
      " Post: 'aaaa meu look de hoje √© da @cea_brasil ‚ù§Ô∏è patrocinadora e dona do look oficial do Rock in Rio! Aproveitem pra acompanhar o perfil da C&A pra ver todos os lookinhos maravilhosos! Amo muito! ‚ù§Ô∏è'\n",
      " Sponsored (True/False): True\n",
      "\n",
      " Post: 'side by side ~ sisters ‚ù§Ô∏è'\n",
      " Sponsored (True/False): True\n",
      "\n",
      " Post:{'sample post'}\n",
      " Sponsored (True/False):\n"
     ]
    }
   ],
   "source": [
    "print(\"Judge whether it is likely that the following caption comes from a post that has been sponsored. If you are very uncertain err rather towards judging 'False'.\\n\\n Post: 'aaaa meu look de hoje √© da @cea_brasil ‚ù§Ô∏è patrocinadora e dona do look oficial do Rock in Rio! Aproveitem pra acompanhar o perfil da C&A pra ver todos os lookinhos maravilhosos! Amo muito! ‚ù§Ô∏è'\\n Sponsored (True/False): True\\n\\n Post: 'side by side ~ sisters ‚ù§Ô∏è'\\n Sponsored (True/False): True\\n\\n Post:{'sample post'}\\n Sponsored (True/False):\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save interrupted run\n",
    "temp_completions = completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7 43]\n",
      " [ 2 48]]\n",
      "[[36 14]\n",
      " [32 18]]\n",
      "[[45  5]\n",
      " [31 19]]\n",
      "[[49  1]\n",
      " [43  7]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions to booleans\n",
    "completions_as_boolean = {}\n",
    "for model in [\"text-ada-001\", \"text-babbage-001\", \"text-curie-001\", \"text-davinci-002\"]:\n",
    "    completions_as_boolean[model] = [True if response.__contains__(\"rue\") \n",
    "                          else False if response.__contains__(\"als\")\n",
    "                          else \"warning\" for response in completions[model]]\n",
    "\n",
    "    # check for bad completions\n",
    "    if \"warning\" in completions[model]: print(\"Warning\")\n",
    "\n",
    "    # obtain confusion matrix\n",
    "\n",
    "    print(confusion_matrix(df[\"predicted_disclosure\"],completions_as_boolean[model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.pkl', 'rb') as f:\n",
    "    pre_df = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before doing this, add something like the true values\n",
    "with open('results.pkl', 'wb') as file:\n",
    "    pkl.dump(completions, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the prompt to get davinci to more positive judgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter at 10\n",
      "Counter at 20\n",
      "Counter at 30\n",
      "0  done\n",
      "Counter at 40\n",
      "Counter at 50\n",
      "Counter at 60\n",
      "1  done\n"
     ]
    }
   ],
   "source": [
    "# Generate classifications for all samples\n",
    "\n",
    "completions ={\"0\":[],\"1\":[]} #{\"text-ada-001\":[], \"text-babbage-001\":[], \"text-curie-001\":[], \"text-davinci-002\":[]}\n",
    "i=0\n",
    "for x in range(2):#,\"text-ada-001\", \"text-babbage-001\", \"text-curie-001\"]:\n",
    "    #i=0\n",
    "    if x==1: time.sleep(65)\n",
    "    for txt in df.loc[:,\"caption\"]:\n",
    "        i+=1\n",
    "        if i%10==0: print(f\"Counter at {i}\")\n",
    "\n",
    "        # timer to stay within my quota\n",
    "        \n",
    "        if x == 0:\n",
    "            prompt = f\"Might the following post have been sponsored? By default, prefer 'True' in case of doubt.\\n\\n Post: 'All my teenage girl dreams come true tonight! Thank you so much @sherrihill for having me perform at New York Fashion week! üñ§#SherriHillNYFW'\\n Potentially Sponsored (True/False): True\\n\\n Post: 'Life imitating #art üé®üé®\\nlive your #fantasy ‚ú®‚ú®\\nStrolling in #beverlyhills #losangeles \\n#Illustration by @donna_adi üé®üé®\\nHappy to be back In #usa #la'\\n Potentially Sponsored (True/False): False\\n\\n Post:{txt}\\n Potentially Sponsored (True/False): \"\n",
    "        elif x ==1:\n",
    "            prompt = f\"Is it likely that the following post have been sponsored? Assume 'True' in case of doubt.\\n\\n Post: 'aaaa meu look de hoje √© da @cea_brasil ‚ù§Ô∏è patrocinadora e dona do look oficial do Rock in Rio! Aproveitem pra acompanhar o perfil da C&A pra ver todos os lookinhos maravilhosos! Amo muito! ‚ù§Ô∏è'\\n Sponsored (True/False): True\\n\\n Post: 'side by side ~ sisters ‚ù§Ô∏è'\\n Sponsored (True/False): True\\n\\n Post:{txt}\\n Sponsored (True/False): \"\n",
    "\n",
    "        \n",
    "\n",
    "        # Generate a response from openai.\n",
    "        # Flexibly choose ada/babbage/curie/davinci as engine. For davinci, use text-davinci-002.\n",
    "        #prompt=(\"warning\")\n",
    "        #if model in [\"text-ada-001\", \"text-babbage-001\"]:\n",
    "        #    if i==1: print(\"pompt1\")\n",
    "        #    prompt=prompt1\n",
    "        #elif model in [\"text-curie-001\", \"text-davinci-002\"]:\n",
    "        #    if i==1: print(\"pompt2\")\n",
    "        #    prompt=prompt2\n",
    "        #else:\n",
    "        #    print(\"warning\")\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=5,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        # Save the response text\n",
    "        completions[str(x)].append(response[\"choices\"][0][\"text\"])\n",
    "    print(str(x),\" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  4]\n",
      " [ 3 12]]\n",
      "[[15  0]\n",
      " [ 8  7]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions to booleans\n",
    "completions_as_boolean = {}\n",
    "for model in [\"0\", \"1\"]:\n",
    "    completions_as_boolean[model] = [True if response.__contains__(\"rue\") \n",
    "                          else False if response.__contains__(\"als\")\n",
    "                          else \"warning\" for response in completions[model]]\n",
    "\n",
    "    # check for bad completions\n",
    "    if \"warning\" in completions[model]: print(\"Warning\")\n",
    "\n",
    "    # obtain confusion matrix\n",
    "\n",
    "    print(confusion_matrix(df[\"predicted_disclosure\"],completions_as_boolean[model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' True',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' True',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' True',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' True',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False',\n",
       "  ' False'],\n",
       " '1': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
