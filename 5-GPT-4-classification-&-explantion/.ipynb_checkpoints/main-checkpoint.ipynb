{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file I seek to improve previous classifications, by letting GPT self-correct its own previous classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import openai\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from GPTclassifier import gptclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"finalexperiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['index'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-15160e9cc4ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# only execute for small experiments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# only get the ones without disclosures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpre_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpre_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_disclosures\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marraylike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4308\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4309\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m     \u001b[0;31m# Unsorted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4151\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mviews\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mother\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mCurrently\u001b[0m \u001b[0m_is_view\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mALWAYS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmulti\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0mto\u001b[0m \u001b[0mavoid\u001b[0m \u001b[0mhaving\u001b[0m \u001b[0mto\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4153\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4155\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'group'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4188\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4189\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"referent\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4190\u001b[0m             t = (\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5589\u001b[0m             \u001b[0mpassed\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msorted\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mNaN\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5590\u001b[0m             \u001b[0msuch\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5591\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5592\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mAlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5593\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['index'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# import large file\n",
    "with open('../2-annotated-dataset-experiments/results.pkl', 'rb') as f:\n",
    "    pre_df = pkl.load(f)\n",
    "\n",
    "# only execute for small experiments\n",
    "# only get the ones without disclosures\n",
    "pre_df.drop(columns=[\"index\"], inplace=True)\n",
    "df = pre_df[pre_df[\"has_disclosures\"]==False].reset_index(drop=True)\n",
    "\n",
    "del pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./texts/system_message.txt', 'r') as file1:\n",
    "    system_message = file1.read()\n",
    "with open('./texts/template.txt', 'r') as file2:\n",
    "    template = file2.read()\n",
    "with open('./texts/examples.pkl', 'rb') as file3:\n",
    "    examples = pkl.load(file3)\n",
    "completions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter at 5\n",
      "Counter at 55\n",
      "Counter at 105\n",
      "Counter at 155\n",
      "Counter at 205\n",
      "Counter at 255\n",
      "Counter at 305\n",
      "Counter at 355\n",
      "Counter at 405\n",
      "Counter at 455\n",
      "Waiting for 65s RateLimitError\n",
      "Counter at 505\n"
     ]
    }
   ],
   "source": [
    "results = gptclassifier(df,system_message, template, examples, completions, timer_frequency=50)\n",
    "\n",
    "with open('results.pkl', 'wb') as file:\n",
    "    pkl.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[\"label\"])\n",
    "# central problem: preference for positive labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['True.',\n",
       " 'True.',\n",
       " 'True.',\n",
       " 'True.',\n",
       " 'True.',\n",
       " 'True.',\n",
       " 'False.',\n",
       " 'False.',\n",
       " 'False.',\n",
       " 'False/Uncertain.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0] # explanations\n",
    "results[1] # boolean labels\n",
    "results[2] # 4 labels as strings (booleans + uncertain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"GPT-4_attempt1\"] = results[1]\n",
    "df[\"GPT-4_unclear_label\"] = results[2]\n",
    "df[\"GPT-4_explanations\"] = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"baseline\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_results.pkl', 'wb') as file:\n",
    "    pkl.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>username</th>\n",
       "      <th>caption</th>\n",
       "      <th>caption_hashtags</th>\n",
       "      <th>tagged_users</th>\n",
       "      <th>tagged_users_full</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>is_ad</th>\n",
       "      <th>caption_is_edited</th>\n",
       "      <th>...</th>\n",
       "      <th>has_sponsored_keywords</th>\n",
       "      <th>has_disclosures</th>\n",
       "      <th>keyword_tfidf</th>\n",
       "      <th>keyword_keybert</th>\n",
       "      <th>captions_task</th>\n",
       "      <th>caption_task</th>\n",
       "      <th>label</th>\n",
       "      <th>GPT-4_attempt1</th>\n",
       "      <th>GPT-4_unclear_label</th>\n",
       "      <th>GPT-4_explanations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>weworewhat</td>\n",
       "      <td>Heading to Sicily to shoot my Italy @weworewha...</td>\n",
       "      <td>['#oniaxweworewhat']</td>\n",
       "      <td>['onia', 'ericjavits', 'bambi_studios', 'shopw...</td>\n",
       "      <td>['onia', 'Eric Javits', 'Bambi Studios —', 'SH...</td>\n",
       "      <td>32211</td>\n",
       "      <td>376</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['with tonight can' 'heading to sicily' 'to si...</td>\n",
       "      <td>['heading sicily shoot', 'shoot italy collecti...</td>\n",
       "      <td>Heading to Sicily to shoot my Italy @weworewha...</td>\n",
       "      <td>Heading to Sicily to shoot my Italy @weworewha...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True.</td>\n",
       "      <td>Thought: Mention of collaboration and product ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>weworewhat</td>\n",
       "      <td>Wearing white as a brunette is so much better ...</td>\n",
       "      <td>['#mango']</td>\n",
       "      <td>['mango']</td>\n",
       "      <td>['MANGO']</td>\n",
       "      <td>26761</td>\n",
       "      <td>320</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['white as brunette' 'much better full' 'as br...</td>\n",
       "      <td>['white brunette better', 'wearing white brune...</td>\n",
       "      <td>Wearing white as a brunette is so much better ...</td>\n",
       "      <td>Wearing white as a brunette is so much better ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True.</td>\n",
       "      <td>Thought: Mention of a brand (@mango) and hasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>weworewhat</td>\n",
       "      <td>been loving no eye makeup and a nude lip • wea...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['hudabeauty']</td>\n",
       "      <td>['HUDA KATTAN']</td>\n",
       "      <td>6684</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['wearing flirt and' 'brow got' 'makeup and nu...</td>\n",
       "      <td>['lip wearing flirt', 'flirt boy brow', 'eye m...</td>\n",
       "      <td>been loving no eye makeup and a nude lip • wea...</td>\n",
       "      <td>been loving no eye makeup and a nude lip • wea...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True.</td>\n",
       "      <td>Thought: Mentions specific brands and products...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>karliekloss</td>\n",
       "      <td>99 years ago today the 19th Amendment was rati...</td>\n",
       "      <td>['#WomensEqualityDay']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>86394</td>\n",
       "      <td>485</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['gender' 'we' 'equality on' 'take 208 years' ...</td>\n",
       "      <td>['19th amendment ratified', 'today 19th amendm...</td>\n",
       "      <td>99 years ago today the 19th Amendment was rati...</td>\n",
       "      <td>99 years ago today the 19th Amendment was rati...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True.</td>\n",
       "      <td>Thought: Mentions a link to an action website ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>ab_bowen</td>\n",
       "      <td>Such a good day in Manchester with @oliviadbuc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>24429</td>\n",
       "      <td>44</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['launch in got' 'in got to' 'the boyyy to' 't...</td>\n",
       "      <td>['good day manchester', 'day manchester launch...</td>\n",
       "      <td>Such a good day in Manchester with @oliviadbuc...</td>\n",
       "      <td>Such a good day in Manchester with @oliviadbuc...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True.</td>\n",
       "      <td>Thought: Mentions a beauty launch event at Pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>487</td>\n",
       "      <td>stephhollman</td>\n",
       "      <td>Good morning from gorgeous Mexico! ☀️🌊 There i...</td>\n",
       "      <td>['#MorningRelaxation', '#TimeToReflect', '#lik...</td>\n",
       "      <td>['liketoknow.it']</td>\n",
       "      <td>['LIKEtoKNOW.it']</td>\n",
       "      <td>1149</td>\n",
       "      <td>68</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['all of the' 'many experiences' 'beach reflec...</td>\n",
       "      <td>['morning gorgeous mexico', 'start day beach',...</td>\n",
       "      <td>Good morning from gorgeous Mexico! ☀️🌊 There i...</td>\n",
       "      <td>Good morning from gorgeous Mexico! ☀️🌊 There i...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True/Uncertain.</td>\n",
       "      <td>Thought: The hashtag #liketkit and mention of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>502</td>\n",
       "      <td>darrenjhardy</td>\n",
       "      <td>Today on DarrenDaily, we discussed the surefir...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>709</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['surefire way to' 'wish others would' 'living...</td>\n",
       "      <td>['life confess living', 'live life confess', '...</td>\n",
       "      <td>Today on DarrenDaily, we discussed the surefir...</td>\n",
       "      <td>Today on DarrenDaily, we discussed the surefir...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True.</td>\n",
       "      <td>Thought: DarrenDaily may be a non-commercial s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>503</td>\n",
       "      <td>darrenjhardy</td>\n",
       "      <td>Do you struggle with recruiting A-Players on y...</td>\n",
       "      <td>['#JoinTheRide', '#linkinbio']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>557</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['recruiting' 'recruiting on your' 'talent to ...</td>\n",
       "      <td>['struggle recruiting team', 'entrepreneur rol...</td>\n",
       "      <td>Do you struggle with recruiting A-Players on y...</td>\n",
       "      <td>Do you struggle with recruiting A-Players on y...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True.</td>\n",
       "      <td>Thought: The link and mention of a free book s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>513</td>\n",
       "      <td>darrenjhardy</td>\n",
       "      <td>WHAT’S NEW ON DARRENDAILY ON-DEMAND THIS WEEK!...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>398</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['ep' 'brand' 'steps' 'badass personal brand' ...</td>\n",
       "      <td>['personal brand steps', 'build brand dreams',...</td>\n",
       "      <td>WHAT’S NEW ON DARRENDAILY ON-DEMAND THIS WEEK!...</td>\n",
       "      <td>WHAT’S NEW ON DARRENDAILY ON-DEMAND THIS WEEK!...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True.</td>\n",
       "      <td>Thought: This post promotes a podcast and enco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>524</td>\n",
       "      <td>jarrylee</td>\n",
       "      <td>honored to be named @ModelMayhem’s Model of th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['jarrylee', 'modelmayhem', 'uga_talent', 'mod...</td>\n",
       "      <td>['JARRY LEE', 'Model Mayhem', 'UGA Talent Agen...</td>\n",
       "      <td>6233</td>\n",
       "      <td>743</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['named model of' 'for january 2019' 'named mo...</td>\n",
       "      <td>['model month january', 'honored named model',...</td>\n",
       "      <td>honored to be named @ModelMayhem’s Model of th...</td>\n",
       "      <td>honored to be named @ModelMayhem’s Model of th...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True.</td>\n",
       "      <td>Thought: Mention of @ModelMayhem and being nam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0      username  \\\n",
       "3             3    weworewhat   \n",
       "4             4    weworewhat   \n",
       "7             7    weworewhat   \n",
       "12           12   karliekloss   \n",
       "20           20      ab_bowen   \n",
       "..          ...           ...   \n",
       "487         487  stephhollman   \n",
       "502         502  darrenjhardy   \n",
       "503         503  darrenjhardy   \n",
       "513         513  darrenjhardy   \n",
       "524         524      jarrylee   \n",
       "\n",
       "                                               caption  \\\n",
       "3    Heading to Sicily to shoot my Italy @weworewha...   \n",
       "4    Wearing white as a brunette is so much better ...   \n",
       "7    been loving no eye makeup and a nude lip • wea...   \n",
       "12   99 years ago today the 19th Amendment was rati...   \n",
       "20   Such a good day in Manchester with @oliviadbuc...   \n",
       "..                                                 ...   \n",
       "487  Good morning from gorgeous Mexico! ☀️🌊 There i...   \n",
       "502  Today on DarrenDaily, we discussed the surefir...   \n",
       "503  Do you struggle with recruiting A-Players on y...   \n",
       "513  WHAT’S NEW ON DARRENDAILY ON-DEMAND THIS WEEK!...   \n",
       "524  honored to be named @ModelMayhem’s Model of th...   \n",
       "\n",
       "                                      caption_hashtags  \\\n",
       "3                                 ['#oniaxweworewhat']   \n",
       "4                                           ['#mango']   \n",
       "7                                                   []   \n",
       "12                              ['#WomensEqualityDay']   \n",
       "20                                                  []   \n",
       "..                                                 ...   \n",
       "487  ['#MorningRelaxation', '#TimeToReflect', '#lik...   \n",
       "502                                                 []   \n",
       "503                     ['#JoinTheRide', '#linkinbio']   \n",
       "513                                                 []   \n",
       "524                                                 []   \n",
       "\n",
       "                                          tagged_users  \\\n",
       "3    ['onia', 'ericjavits', 'bambi_studios', 'shopw...   \n",
       "4                                            ['mango']   \n",
       "7                                       ['hudabeauty']   \n",
       "12                                                  []   \n",
       "20                                                  []   \n",
       "..                                                 ...   \n",
       "487                                  ['liketoknow.it']   \n",
       "502                                                 []   \n",
       "503                                                 []   \n",
       "513                                                 []   \n",
       "524  ['jarrylee', 'modelmayhem', 'uga_talent', 'mod...   \n",
       "\n",
       "                                     tagged_users_full  likes  comments  \\\n",
       "3    ['onia', 'Eric Javits', 'Bambi Studios —', 'SH...  32211       376   \n",
       "4                                            ['MANGO']  26761       320   \n",
       "7                                      ['HUDA KATTAN']   6684        98   \n",
       "12                                                  []  86394       485   \n",
       "20                                                  []  24429        44   \n",
       "..                                                 ...    ...       ...   \n",
       "487                                  ['LIKEtoKNOW.it']   1149        68   \n",
       "502                                                 []    709         7   \n",
       "503                                                 []    557         6   \n",
       "513                                                 []    398         5   \n",
       "524  ['JARRY LEE', 'Model Mayhem', 'UGA Talent Agen...   6233       743   \n",
       "\n",
       "     is_ad  caption_is_edited  ... has_sponsored_keywords has_disclosures  \\\n",
       "3    False              False  ...                  False           False   \n",
       "4    False              False  ...                  False           False   \n",
       "7    False              False  ...                  False           False   \n",
       "12   False              False  ...                  False           False   \n",
       "20   False              False  ...                  False           False   \n",
       "..     ...                ...  ...                    ...             ...   \n",
       "487  False               True  ...                  False           False   \n",
       "502  False               True  ...                  False           False   \n",
       "503  False               True  ...                  False           False   \n",
       "513  False               True  ...                  False           False   \n",
       "524  False              False  ...                  False           False   \n",
       "\n",
       "                                         keyword_tfidf  \\\n",
       "3    ['with tonight can' 'heading to sicily' 'to si...   \n",
       "4    ['white as brunette' 'much better full' 'as br...   \n",
       "7    ['wearing flirt and' 'brow got' 'makeup and nu...   \n",
       "12   ['gender' 'we' 'equality on' 'take 208 years' ...   \n",
       "20   ['launch in got' 'in got to' 'the boyyy to' 't...   \n",
       "..                                                 ...   \n",
       "487  ['all of the' 'many experiences' 'beach reflec...   \n",
       "502  ['surefire way to' 'wish others would' 'living...   \n",
       "503  ['recruiting' 'recruiting on your' 'talent to ...   \n",
       "513  ['ep' 'brand' 'steps' 'badass personal brand' ...   \n",
       "524  ['named model of' 'for january 2019' 'named mo...   \n",
       "\n",
       "                                       keyword_keybert  \\\n",
       "3    ['heading sicily shoot', 'shoot italy collecti...   \n",
       "4    ['white brunette better', 'wearing white brune...   \n",
       "7    ['lip wearing flirt', 'flirt boy brow', 'eye m...   \n",
       "12   ['19th amendment ratified', 'today 19th amendm...   \n",
       "20   ['good day manchester', 'day manchester launch...   \n",
       "..                                                 ...   \n",
       "487  ['morning gorgeous mexico', 'start day beach',...   \n",
       "502  ['life confess living', 'live life confess', '...   \n",
       "503  ['struggle recruiting team', 'entrepreneur rol...   \n",
       "513  ['personal brand steps', 'build brand dreams',...   \n",
       "524  ['model month january', 'honored named model',...   \n",
       "\n",
       "                                         captions_task  \\\n",
       "3    Heading to Sicily to shoot my Italy @weworewha...   \n",
       "4    Wearing white as a brunette is so much better ...   \n",
       "7    been loving no eye makeup and a nude lip • wea...   \n",
       "12   99 years ago today the 19th Amendment was rati...   \n",
       "20   Such a good day in Manchester with @oliviadbuc...   \n",
       "..                                                 ...   \n",
       "487  Good morning from gorgeous Mexico! ☀️🌊 There i...   \n",
       "502  Today on DarrenDaily, we discussed the surefir...   \n",
       "503  Do you struggle with recruiting A-Players on y...   \n",
       "513  WHAT’S NEW ON DARRENDAILY ON-DEMAND THIS WEEK!...   \n",
       "524  honored to be named @ModelMayhem’s Model of th...   \n",
       "\n",
       "                                          caption_task  label GPT-4_attempt1  \\\n",
       "3    Heading to Sicily to shoot my Italy @weworewha...  False           True   \n",
       "4    Wearing white as a brunette is so much better ...  False           True   \n",
       "7    been loving no eye makeup and a nude lip • wea...  False           True   \n",
       "12   99 years ago today the 19th Amendment was rati...  False           True   \n",
       "20   Such a good day in Manchester with @oliviadbuc...  False           True   \n",
       "..                                                 ...    ...            ...   \n",
       "487  Good morning from gorgeous Mexico! ☀️🌊 There i...  False           True   \n",
       "502  Today on DarrenDaily, we discussed the surefir...  False           True   \n",
       "503  Do you struggle with recruiting A-Players on y...  False           True   \n",
       "513  WHAT’S NEW ON DARRENDAILY ON-DEMAND THIS WEEK!...  False           True   \n",
       "524  honored to be named @ModelMayhem’s Model of th...  False           True   \n",
       "\n",
       "    GPT-4_unclear_label                                 GPT-4_explanations  \n",
       "3                 True.  Thought: Mention of collaboration and product ...  \n",
       "4                 True.  Thought: Mention of a brand (@mango) and hasht...  \n",
       "7                 True.  Thought: Mentions specific brands and products...  \n",
       "12                True.  Thought: Mentions a link to an action website ...  \n",
       "20                True.  Thought: Mentions a beauty launch event at Pri...  \n",
       "..                  ...                                                ...  \n",
       "487     True/Uncertain.  Thought: The hashtag #liketkit and mention of ...  \n",
       "502               True.  Thought: DarrenDaily may be a non-commercial s...  \n",
       "503               True.  Thought: The link and mention of a free book s...  \n",
       "513               True.  Thought: This post promotes a podcast and enco...  \n",
       "524               True.  Thought: Mention of @ModelMayhem and being nam...  \n",
       "\n",
       "[158 rows x 44 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"label\"]!=df[\"GPT-4_attempt1\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
